---
title: "Taking the Bayesian Leap"
subtitle: "Maud goes to Vegas"
author: Andrew B. Collier
location: eRum (Budapest)
date: 15 May 2018
title_logo:
- "img/logo-toptal.png"
- "img/logo-exegetic.svg"
output: 
  revealjs::revealjs_presentation:
    self_contained: false
    transition: none
    reveal_plugins: ["zoom", "notes"]
    template: datawookie-reveal-markdown-template.html
    css: datawookie-reveal-markdown.css
---

<!--
    Other resources:

    - http://rpubs.com/pviefers/CologneR [has interesting example of hierarchical model]
    - https://www.youtube.com/watch?v=s-9itaL1v-o "Extending the Power of R with Stan" [focus on rstanarm package]
    - https://vimeo.com/132156595

    - http://m-clark.github.io/docs/IntroBayes.html
    - https://www.youtube.com/watch?v=uSjsJg8fcwY [Michael Betancourt - "Some Bayesian Modeling Techniques in Stan"]
    - https://www.youtube.com/watch?v=qQFF4tPgeWI [Bob Carpenter]
    - https://www.youtube.com/watch?v=pHsuIaPbNbY [Michael Betancourt - "Efficient Bayesian inference with Hamiltonian Monte Carlo"]
    
    - https://matthewdharris.com/2016/10/18/estimating-a-beta-distribution-with-stan-hmc/
    - http://blackwell.math.yorku.ca/MATH6635/2016/Day17/MCMC_with_STAN_examples.html
-->

```{r setup, include=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)

library(rstan)
library(dplyr)
# library(purrr)
library(ggplot2)
library(knitr)
```

![](img/logo-toptal.png)

<aside class="notes">
Enough about me. I want you to meet somebody else.
</aside>

## {data-background="img/maud-introduction.svg" data-background-size="50%" data-background-position="left bottom"}

<aside class="notes">
Meet my friend Maud.

Maud is 71. She likes cats and gardening. SOMETHING ELSE.

Maud has a gambling problem.
</aside>

## {data-background="img/maud-love-r.svg" data-background-size="50%" data-background-position="left bottom"}

## {data-background="img/slot-machine.jpg"}

# Cats vs Mice

## Paytable

```{r include=FALSE}
paytable <- data.frame(
  payout = c(0, 1, 2, 5, 10, 20, 100),
  frequency = c(700, 166, 80, 33, 15, 5, 1),
  symbol = c("", rep(c("mouse", "cat"), 3)),
  repeats = c(0, 1, 1, 2, 2, 3, 3),
  stringsAsFactors = FALSE
) %>% mutate(
  symbols = purrr::map2(symbol, repeats, function(sym, n) {ifelse(sym == "", "", emo::ji(sym)) %>% rep(n) %>% paste(collapse = "")})
) %>% select(frequency, payout, symbols)
```
```{r paytable}
paytable
```
```{r include=FALSE}
paytable <- paytable %>% mutate(
  probability = frequency / sum(frequency)
)
```

## Data

```{r create_data, include=FALSE}
SESSIONS <- 100
AVGSPINS <- 20

# Probability of wagering 1, 2 or 3 coins per spin.
#
COINPROB = c(0.8, 0.15, 0.05)

sessions <- tibble(
  spins = rpois(SESSIONS, AVGSPINS)
) %>% mutate(
  # Generate samples for individual spins.
  #
  details = purrr::pmap(., function(spins) {
    data.frame(
      spin = 1:spins,
      wager = sample(1:3, spins, replace = TRUE, prob = COINPROB)
    ) %>% mutate(
      payout = sample(paytable$payout, spins, TRUE, paytable$frequency) * wager
    )
  }),
  session = 1:SESSIONS
)

sessions <- inner_join(
  sessions,
  sessions %>%
    tidyr::unnest() %>%
    group_by(session) %>%
    summarise(
      hits = sum(payout > 0),
      wager = sum(wager),
      payout = sum(payout)
    )
) %>%
  mutate(
    hit_rate = hits / spins,
    rtp = payout / wager
  ) %>%
  select(session, details, everything())
```

```{r}
head(sessions)
```

## Hit Rate

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(sessions, aes(x = hit_rate)) +
  geom_histogram() +
  scale_x_continuous("Hit Rate", limits = c(0, 1))
```

```{r include=FALSE}
y = c(0, 0, 1, 1, 1)

# Log-likelihood of a parameter value given the data.
#
bernoulli_likelihood <- function(theta, y) {
  sum(y * log(theta) + (1 - y) * log(1 - theta))
}

bernoulli_likelihood(0.3, y)
bernoulli_likelihood(0.6, y)
```

```{r include=FALSE}
binom_likelihood <- function(theta, k, n) {
  prod(choose(n, k) * theta^k * (1 - theta)^(n - k))
  #
  # Equivalent to dbinom(k, size = n, prob = theta)
}

# Neglect the choose(n, k) since it's a constant (as a function of theta).
#
# theta - probability [single value]
# k - number of successes [vector]
# n - number of trials [vector]
#
binom_log_likelihood <- function(theta, k, n) {
  sum(k * log10(theta) + (n - k) * log10(1 - theta))
}
```

<aside class="notes">
For many applications, the natural logarithm of the likelihood function,
called the log-likelihood, is more convenient to work with. Because the
logarithm is a strictly increasing function, the logarithm of a function
achieves its maximum value at the same points as the function itself, and
hence the log-likelihood can be used in place of the likelihood in maximum
likelihood estimation and related techniques. Finding the maximum of a
function often involves taking the derivative of a function and solving for
the parameter being maximized, and this is often easier when the function
being maximized is a log-likelihood rather than the original likelihood
function.
</aside>

## Maximum Likelihood

```{r}
binom_likelihood(0.6, sessions$hits, sessions$spins)
binom_log_likelihood(0.6, sessions$hits, sessions$spins)

parameters <- tibble(theta = seq(0, 1, 0.02)) %>%
  mutate(
    likelihood = sapply(theta, binom_likelihood, sessions$hits, sessions$spins),
    log_likelihood = sapply(theta, binom_log_likelihood, sessions$hits, sessions$spins)
  )

ggplot(parameters, aes(theta, log_likelihood)) + geom_point()

parameters %>% arrange(desc(log_likelihood)) %>% head()
```

<blockquote>
For now, weneedtolearnhowtocombinesamplingofsimulatedobservations, as in the previous section, with sampling parameters from the posterior distribution. We expect to dobetter whenweusetheentireposterior distribution, not just some point estimate derived from it. Why? Because there is a lot of information about uncertainty in the entire posterior distribution. We lose this information when we pluck out a single parameter value and then perform calculations with it. This loss of information leads to overconfidence.
</blockquote>

<aside class="notes">
IF WE WERE TAKING MAXIMUM LIKELIHOOD APPROACH THEN WE WOULD JUST CHOOSE THETA WHICH MAXIMISES LIKELIHOOD.

BAYESIAN APPROACH IS DIFFERENT BECAUSE WE FACTOR IN EXISTING BELIEFS ABOUT THE DISTRIBUTION OF THETA.

This gives us a point estimate for the parameter.
</aside>

## Bayesian

<blockquote>
T hegreatest obstacle that I encounter among students and colleagues is the tacit belief that the proper objective of statistical inference is to test null hypotheses.3 This is the proper objective, the thinking goes, because Karl Popper argued that science advances by falsifying hypotheses. Karl Popper (1902–1994) is possibly the most influential philosopher of science, at least among scientists. He did persuasively argue that science works better by developing hypotheses that are, in principle, falsifiable. Seeking out evidence that might embarrass our ideasis anormativestandard,andonethatmostscholars—whethertheydescribethemselves as scientists or not—subscribe to. So maybe statistical procedures should falsify hypotheses, if we wish to be good statistical scientists.
</blockquote>

## Bayesian: Not everybody's a fan

<blockquote>
... the theory of inverse probability is founded upon error and must be wholly rejected.
<cite>Sir Ronald Fisher (1925)</cite>
</blockquote>

<aside class="notes">
Historically the Bayesian approach has been marginalised by some eminent statisticians. For example, Ronald Fisher had this to say about inverse probability as Bayesian inference was known in his day.
</aside>

## Bayesian Inference

Data $y$ and a model with parameters $\theta$.

Bayes' Theorem
$$
p(\theta|y, X) = \frac{p(y|X, \theta) p(\theta)}{p(y)} \propto p(y|\theta) p(\theta)
$$
where

- prior — $p(\theta)$ is parameter distribution <em>before</em> data;
- likelihood — $p(y|X, \theta)$ is probability of data <em>given</em> parameters; and
- posterior — $p(\theta|y, X)$ is parameter distribution <em>given</em> data.

<aside class="notes">
A Bayesian model is the combination of the prior and the likelihood.
</aside>

## Example: Bernoulli and Binomial Likelihoods

$$
p(y|\theta) = \binom{n}{y} \theta^y (1 - \theta)^{n - y}
$$

<aside class="notes">
With more complicated models it is seldom possible to write an analytical expression for the posterior.
</aside>

## So much for Theory...

Analytical expressions are rare in practice.

Confounding features:

- data are often multi-dimensional;
- models have multiple parameters.

So evaluating $p(\theta|y)$ becomes challenging!

## Grid Approximation

```{r}
prior <- tibble(
  theta = seq(0, 1, 0.02),
  update = 0
)

prior_unif <- prior %>% mutate(
  p = 1
)
prior_trig <- prior %>% mutate(
  p = ifelse(theta < 0.5, 2 * theta, 2 - 2 * theta)
)

binom_update <- function(prior, k, n) {
  likelihood <- sapply(prior$theta, binom_likelihood, k, n)
  #
  prior %>% mutate(
    # Update.
    p = likelihood * p,
    # Normalise.
    p = p / sum(p)
  )
}

plot(p ~ theta, prior_unif)
plot(p ~ theta, binom_update(prior_unif, 1, 3))

plot(p ~ theta, prior_trig)
plot(p ~ theta, binom_update(prior_trig, 1, 3))
```

<aside class="notes">
In the grid approximation we consider a finite number of points at which we evaluate the prior and likelihood. Their product then gives us the posterior at each of those points.

There's a major problem with the grid approximation: it scales poorly with the number of parameters in the model and rapidly becomes computationally intractable.
</aside>

## foo

```{r}
for (n in 1:11) {
  hits = sessions[[n, "hits"]]
  spins = sessions[[n, "spins"]]
  prior_unif <- rbind(prior_unif, binom_update(prior_unif %>% filter(update == n - 1), hits, spins) %>% mutate(update = update + 1))
  prior_trig <- rbind(prior_trig, binom_update(prior_trig %>% filter(update == n - 1), hits, spins) %>% mutate(update = update + 1))
}

prior_unif$prior = "Uniform"
prior_trig$prior = "Triangle"
#
priors = rbind(prior_unif, prior_trig)
```

## foo

```{r}
ggplot(prior_unif, aes(x = theta, y = p)) +
  geom_line() +
  geom_point() +
  facet_wrap(~ update, scales = "free_y")
```

## foo

```{r}

ggplot(prior_trig, aes(x = theta, y = p)) +
  geom_line() +
  geom_point() +
  facet_wrap(~ update, scales = "free_y")
```

## foo

```{r}

ggplot(priors, aes(x = theta, y = p)) +
  geom_line(aes(col = prior)) +
  # geom_point() +
  facet_wrap(~ update, scales = "free_y")
```

## ... resort to Simulation!

Metropolis-Hastings algorithm.

## More Efficient Simulation!

Hamiltonian Monte Carlo.

The NUTS sampling algorithm is *much* more efficient than vanilla MCMC.

Treat the parameter vector like the coordinates of a particle on a potential energy surface, where the potential energy is the negative log posterior.

## Stan Skeleton

<script src="https://gist.github.com/DataWookie/61d7a662ecaad87044e1c9f161a5245f.js"></script>

## Image

<img src="https://cdn.rawgit.com/stan-dev/logos/0f0922d5/logo_name_banner.svg" />

High level language for writing statistical models.

## Bare Bones Stan

<script src="https://gist.github.com/DataWookie/61d7a662ecaad87044e1c9f161a5245f.js"></script>

## Running Stan from R

Stan workflow:

- Write Stan program.
- Stan parser converts this to C++.
- Compile C++.
- Execute compiled binary.

Requirements:

- `.R` file
- `.stan` file

Using `rstan`:

- RStudio recognises `.stan` files.
- Steps automated.



<aside class="notes">
1. Represent a statistical model by writing its log posterior density (up to
an normalizing constant that does not depend on the unknown parameters in the
model) using the Stan modeling language. We recommend using a separate file
with a .stan extension, although it can also be done using a character string
within R.
2. Translate the Stan program to C++ code using the stanc function.
3. Compile the C++ code to create a DSO (also called a dynamic link library
(DLL)) that can be loaded by R.
4. Run the DSO to sample from the posterior distribution.
5. Diagnose non-convergence of the MCMC chains.
6. Conduct inference based on the posterior sample (the MCMC draws from the
posterior distribution).

As mentioned earlier in the vignette, Stan programs are written in the Stan
modeling language, translated to C++ code, and then compiled to a dynamic
shared object (DSO). The DSO is then loaded by R and executed to draw the
posterior sample. The process of compiling C++ code to DSO sometimes takes a
while. When the model is the same, we can reuse the DSO from a previous run.
The stan function accepts the optional argument fit, which can be used to pass
an existing fitted model object so that the compiled model is reused. When
reusing a previous fitted model, we can still specify different values for the
other arguments to stan, including passing different data to the data
argument.

In addition, if fitted models are saved using functions like save and
save.image, RStan is able to save DSOs, so that they can be used across R
sessions. To avoid saving the DSO, specify save_dso=FALSE when calling the
stan function.
</aside>

## Stan 1 .stan

```{r echo=FALSE, cache=FALSE}
read_chunk("sessions-binomial-no-prior.stan")
```

```{text stan_binomial_no_prior, message=FALSE, warning=FALSE, eval=FALSE}
```

<aside class="notes">
The ~ represents a stochastic relationship. An = would indicate a deterministic relationship.

The number of Markov chains to run can be specified using the chains argument
to the stan or sampling functions. By default, the chains are executed
serially (i.e., one at a time) using the parent R process. There is also an
optional cores argument that can be set to the number of chains (if the
hardware has sufficient processors and RAM), which is appropriate on most
laptops. We typically recommend first calling
options(mc.cores=parallel::detectCores()) once per R session so that all
available cores can be used without needing to manually specify the cores
argument.
</aside>

## Stan 1 .R

```{r message=FALSE, warning=FALSE, results='hide', cache=TRUE}
library(rstan)

trials <- list(
  N       = nrow(sessions),
  hits    = sessions$hits,
  spins   = sessions$spins
)

fit <- stan(
  file    = "sessions-binomial-no-prior.stan",
  data    = trials,
  chains  = 4,                         # Number of Markov chains
  warmup  = 1000,                      # Number of warmup iterations per chain
  iter    = 2000,                      # Total number of iterations per chain
  refresh = 1000                       # Iterations between status update
)
```

<aside class="notes">
We're being rather vague here and not specifying a prior on the model parameter. As a result Stan uses the uniformative uniform prior by default.
</aside>

## Stan Results

```{r}
fit
```

<aside class="notes">
`n_eff` is the effective number of samples.
</aside>

# Stan 1a

```{r stan_binomial_uniform_prior, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
library(rstan)

trials <- list(
  N       = nrow(sessions),
  hits    = sessions$hits,
  spins   = sessions$spins
)

fit <- stan(
  file    = "sessions-binomial-uniform-prior.stan",
  data    = trials,
  chains  = 4,
  warmup  = 1000,
  iter    = 2000,
  refresh = 1000
)
```

# Stan 1a

```{r stan_binomial_beta_prior, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
library(rstan)

trials <- list(
  N       = nrow(sessions),
  hits    = sessions$hits,
  spins   = sessions$spins
)

fit <- stan(
  file    = "sessions-binomial-beta-prior.stan",
  data    = trials,
  chains  = 4,
  warmup  = 1000,
  iter    = 2000,
  refresh = 1000
)
```

## Stan 2

```{r}
# Stan is generating draws from the posterior and the results (below) are based on those draws.

print(fit, pars=c("mu", "lp__"), probs=c(.1,.5,.9))

plot(fit)

# posterior_interval(fit, prob = 0.5) # Is this function from rstanarm?
#
# You can literally say that "there is a 25% chance that it's smaller than..."

traceplot(fit, pars = c("mu"), inc_warmup = TRUE, nrow = 2)

pairs(fit, pars = c("mu", "lp__"), las = 1)
```

---

```{r}
plot(fit, show_density = TRUE, ci_level = 0.5, fill_color = "purple")
```
---

```{r}
plot(fit, plotfun = "hist", pars = "mu", include = FALSE)
```
---

```{r}
plot(fit, plotfun = "trace", pars = c("mu"), inc_warmup = TRUE) + ggtitle("Example of adding title to plot")
```

## Stan 3

```{r stan_poisson, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
trials <- list(
  N       = nrow(sessions),
  spins   = sessions$spins
)

fit <- stan(
  file    = "sessions-poisson.stan",
  data    = trials,
  chains  = 4,
  warmup  = 1000,
  iter    = 2000,
  refresh = 1000
)
```

## Stan

```{r}
extract(fit)

# hist(extract(fit)$lambda)
```

<aside class="notes">
These are samples from the posterior.
</aside>

## Stan 4

```{r cache=TRUE}
ggplot(sessions, aes(x = payout / wager)) + geom_histogram()
```

## Stan 5

```{r echo=FALSE, cache=FALSE}
read_chunk("sessions-normal.stan")
```

```{text stan_normal, message=FALSE, warning=FALSE, eval=FALSE}
```

<aside class="notes">
I know that the explicit loop is probably making you cringe. But Stan converts this into C++ code. And that code is compiled. The loop actually ends up being remarkably efficient.
</aside>

## Stan 6

```{r message=FALSE, warning=FALSE, results='hide', cache=TRUE}
trials <- list(
  N       = nrow(sessions),
  wager   = sessions$wager,
  payout  = sessions$payout
)

fit <- stan(
  file    = "sessions-normal.stan",
  data    = trials,
  chains  = 4,
  warmup  = 1000,
  iter    = 2000,
  refresh = 1000
)
```

## Stan 7

```{r}
pairs(fit, pars = c("mu", "sigma", "lp__"), las = 1)
```

## Regression

```{r}
ggplot(sessions, aes(spins, wager)) + geom_jitter()
```

## Regression Stan

```{r echo=FALSE, cache=FALSE}
read_chunk("sessions-regression.stan")
```

```{text stan_regression, message=FALSE, warning=FALSE, eval=FALSE}
```

## Regression Stan R

```{r cache=TRUE}
trials <- list(
  N       = nrow(sessions),
  x       = sessions$spins,
  y       = sessions$wager
)

options(mc.cores = parallel::detectCores())

fit <- stan(
  file    = "sessions-regression.stan",
  data    = trials,
  chains  = 4,
  warmup  = 1000,
  iter    = 2000,
  refresh = 1000
)
```

## Predictive Inference



## Parameter Uncertainty

Frequentist approach does not quantify uncertainty in model parameters.

## Distribution of Hit Rate

What is the distribution of the hit rate?

(Spoiler: It's not Normal.)

## ShinyStan

library(shinystan)
launch_shinystan(fit)
#
# Diagnose -> PPcheck "Posterior predictive check" (look at distribution of observed data versus replications - do they look similar? "If our model is a good fit then we should be able to use it to generate data that looks a lot like the data we observed.")


## Resources

- http://mc-stan.org/workshops/
- <a href="http://mc-stan.org/">Stan web site</a>
- <a href="http://www.mcmchandbook.net/HandbookChapter5.pdf">MCMC Using Hamiltonian Dynamics</a> (Radford Neal)
- Blogs:
  - <http://andrewgelman.com/>
